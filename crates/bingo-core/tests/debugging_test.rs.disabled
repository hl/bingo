//! Test advanced rule debugging and performance profiling functionality

use bingo_core::*;
use std::collections::HashMap;

#[test]
fn test_debug_manager_initialization() {
    println!("ðŸ”§ Debug Manager Initialization Test");
    println!("==================================");
    
    let mut debug_manager = DebugManager::new();
    
    println!("ðŸ“Š Testing debug manager initialization...");
    
    // Check initial state
    let stats = debug_manager.get_stats();
    assert_eq!(stats.total_sessions, 0);
    assert_eq!(stats.total_traces, 0);
    
    println!("  Initial sessions: {}", stats.total_sessions);
    println!("  Initial traces: {}", stats.total_traces);
    
    // Create a debugging session
    let rule_ids = vec![1, 2, 3];
    let session_id = debug_manager.create_session(rule_ids.clone(), None);
    
    // Verify session was created
    let updated_stats = debug_manager.get_stats();
    assert_eq!(updated_stats.total_sessions, 1);
    
    println!("  Session created: {}", session_id);
    println!("  Updated sessions: {}", updated_stats.total_sessions);
    println!("  âœ… Debug manager initialization working correctly!");
}

#[test]
fn test_execution_trace_creation() {
    println!("ðŸ“‹ Execution Trace Creation Test");
    println!("===============================");
    
    let mut debug_manager = DebugManager::new();
    
    println!("ðŸ“Š Testing execution trace creation...");
    
    // Create test fact
    let mut fact_fields = HashMap::new();
    fact_fields.insert("temperature".to_string(), FactValue::Integer(75));
    fact_fields.insert("location".to_string(), FactValue::String("office".to_string()));
    
    let test_fact = Fact {
        id: 1,
        data: FactData { fields: fact_fields },
    };
    
    // Start execution trace
    let rule_id = 100;
    let trace_id = debug_manager.start_trace(rule_id, test_fact.clone());
    
    // Verify trace was created
    let stats = debug_manager.get_stats();
    assert_eq!(stats.total_traces, 1);
    
    println!("  Trace created: {}", trace_id);
    println!("  Rule ID: {}", rule_id);
    println!("  Input fact ID: {}", test_fact.id);
    
    // Complete trace with result
    let execution_result = ExecutionResult::RuleFired {
        actions_executed: 2,
        facts_created: vec![test_fact.clone()],
    };
    
    debug_manager.complete_trace(trace_id, execution_result);
    
    println!("  Trace completed successfully");
    println!("  âœ… Execution trace creation working correctly!");
}

#[test]
fn test_performance_profiling() {
    println!("ðŸ“Š Performance Profiling Test");
    println!("============================");
    
    let mut debug_manager = DebugManager::new();
    
    println!("ðŸ“Š Testing rule performance profiling...");
    
    let rule_id = 42;
    
    // Create multiple traces to build up performance profile
    for i in 1..=5 {
        let mut fact_fields = HashMap::new();
        fact_fields.insert("iteration".to_string(), FactValue::Integer(i));
        fact_fields.insert("value".to_string(), FactValue::Integer(i * 10));
        
        let test_fact = Fact {
            id: i as u64,
            data: FactData { fields: fact_fields },
        };
        
        let trace_id = debug_manager.start_trace(rule_id, test_fact.clone());
        
        // Simulate some processing time
        std::thread::sleep(std::time::Duration::from_millis(10 + i as u64));
        
        let execution_result = if i % 2 == 0 {
            ExecutionResult::RuleFired {
                actions_executed: 1,
                facts_created: vec![test_fact],
            }
        } else {
            ExecutionResult::ConditionsNotMet {
                failed_conditions: vec!["Value too low".to_string()],
            }
        };
        
        debug_manager.complete_trace(trace_id, execution_result);
    }
    
    // Get performance profile
    let profile = debug_manager.get_rule_profile(rule_id);
    assert!(profile.is_some());
    
    let profile = profile.unwrap();
    assert_eq!(profile.rule_id, rule_id);
    assert_eq!(profile.evaluation_count, 5);
    assert_eq!(profile.fire_count, 2); // Only even iterations fired
    assert!(profile.success_rate > 0.0);
    assert!(profile.success_rate < 1.0);
    
    println!("  Rule ID: {}", profile.rule_id);
    println!("  Evaluations: {}", profile.evaluation_count);
    println!("  Fires: {}", profile.fire_count);
    println!("  Success rate: {:.2}%", profile.success_rate * 100.0);
    println!("  Average execution time: {:?}", profile.average_execution_time);
    
    // Analyze bottlenecks
    let bottlenecks = debug_manager.analyze_bottlenecks(rule_id);
    println!("  Bottlenecks identified: {}", bottlenecks.len());
    
    for bottleneck in &bottlenecks {
        println!("    {:?}: {} (severity: {:.2})", 
                bottleneck.bottleneck_type, 
                bottleneck.description,
                bottleneck.severity);
    }
    
    println!("  âœ… Performance profiling working correctly!");
}

#[test]
fn test_rete_network_debugging_integration() {
    println!("ðŸ”— RETE Network Debugging Integration Test");
    println!("=========================================");
    
    println!("ðŸ“Š Testing RETE network debugging integration...");
    
    let mut engine = ReteNetwork::new().unwrap();
    
    // Enable debugging
    let debug_manager = engine.enable_debugging();
    assert!(engine.is_debugging_enabled());
    
    println!("  Debugging enabled: {}", engine.is_debugging_enabled());
    
    // Create a simple rule
    let conditions = vec![Condition::Simple {
        field: "temperature".to_string(),
        operator: Operator::GreaterThan,
        value: FactValue::Integer(70),
    }];
    
    let actions = vec![Action {
        action_type: ActionType::CreateFact {
            template: FactData {
                fields: {
                    let mut fields = HashMap::new();
                    fields.insert("alert".to_string(), FactValue::String("High temperature detected".to_string()));
                    fields.insert("severity".to_string(), FactValue::String("warning".to_string()));
                    fields
                },
            },
        },
    }];
    
    let rule = Rule {
        id: 1,
        name: "Temperature Alert".to_string(),
        conditions,
        actions,
        priority: 1,
    };
    
    engine.add_rule(rule).unwrap();
    
    // Create debugging session for this rule
    let session_id = engine.create_debug_session(vec![1]);
    assert!(session_id.is_some());
    
    println!("  Debug session created: {:?}", session_id);
    
    // Create test facts
    let mut test_facts = Vec::new();
    for temp in [65, 75, 80, 68, 85] {
        let mut fact_fields = HashMap::new();
        fact_fields.insert("temperature".to_string(), FactValue::Integer(temp));
        fact_fields.insert("location".to_string(), FactValue::String("office".to_string()));
        
        test_facts.push(Fact {
            id: temp as u64,
            data: FactData { fields: fact_fields },
        });
    }
    
    // Process facts with debugging
    let results = engine.process_facts_with_debugging(test_facts.clone(), session_id);
    assert!(results.is_ok());
    
    let results = results.unwrap();
    println!("  Processing results: {} facts created", results.len());
    
    // Should have created alerts for temperatures > 70 (75, 80, 85)
    assert!(results.len() >= 3);
    
    // Get performance profile
    let profile = engine.get_rule_performance_profile(1);
    if let Some(profile) = profile {
        println!("  Rule performance:");
        println!("    Evaluations: {}", profile.evaluation_count);
        println!("    Fires: {}", profile.fire_count);
        println!("    Success rate: {:.2}%", profile.success_rate * 100.0);
        println!("    Avg execution time: {:?}", profile.average_execution_time);
    }
    
    // Get optimization recommendations
    let optimizations = engine.generate_optimization_recommendations();
    println!("  Optimization recommendations: {}", optimizations.len());
    
    for opt in &optimizations {
        println!("    {:?}: {} (improvement: {:.1}%)", 
                opt.optimization_type, 
                opt.description,
                opt.potential_improvement);
    }
    
    // Get debug statistics
    if let Some(debug_stats) = engine.get_debug_stats() {
        println!("  Debug statistics:");
        println!("    Total sessions: {}", debug_stats.total_sessions);
        println!("    Total traces: {}", debug_stats.total_traces);
        println!("    Optimization opportunities: {}", debug_stats.optimization_opportunities.len());
    }
    
    // Test disabling debugging
    engine.disable_debugging();
    assert!(!engine.is_debugging_enabled());
    
    println!("  Debugging disabled: {}", !engine.is_debugging_enabled());
    println!("  âœ… RETE network debugging integration working correctly!");
}

#[test]
fn test_breakpoint_functionality() {
    println!("ðŸš¦ Breakpoint Functionality Test");
    println!("===============================");
    
    let mut debug_manager = DebugManager::new();
    
    println!("ðŸ“Š Testing breakpoint functionality...");
    
    // Create debugging session
    let session_id = debug_manager.create_session(vec![1, 2], None);
    
    // Set different types of breakpoints
    let node_id = 100;
    
    // Set always-break breakpoint
    debug_manager.set_breakpoint(session_id, node_id, BreakpointCondition::Always).unwrap();
    println!("  Set always-break breakpoint on node {}", node_id);
    
    // Test breakpoint with simple token
    let mut fact_fields = HashMap::new();
    fact_fields.insert("test".to_string(), FactValue::String("value".to_string()));
    
    let test_fact = Fact {
        id: 999,
        data: FactData { fields: fact_fields },
    };
    
    let test_token = Token::new(test_fact.id);
    
    // Should break on always condition
    let should_break = debug_manager.should_break(session_id, node_id, &test_token);
    assert!(should_break);
    
    println!("  Breakpoint triggered: {}", should_break);
    
    // Set fact-specific breakpoint
    let fact_node_id = 101;
    debug_manager.set_breakpoint(session_id, fact_node_id, BreakpointCondition::FactId(999)).unwrap();
    
    // Should break for the specific fact
    let should_break_fact = debug_manager.should_break(session_id, fact_node_id, &test_token);
    assert!(should_break_fact);
    
    // Should not break for different fact
    let mut other_fact_fields = HashMap::new();
    other_fact_fields.insert("other".to_string(), FactValue::String("test".to_string()));
    
    let other_fact = Fact {
        id: 888,
        data: FactData { fields: other_fact_fields },
    };
    
    let other_token = Token::new(other_fact.id);
    let should_not_break = debug_manager.should_break(session_id, fact_node_id, &other_token);
    assert!(!should_not_break);
    
    println!("  Fact-specific breakpoint working correctly");
    
    // Set hit count breakpoint
    let hit_count_node_id = 102;
    debug_manager.set_breakpoint(session_id, hit_count_node_id, BreakpointCondition::HitCount(3)).unwrap();
    
    // Should not break on first few hits
    for i in 1..3 {
        let should_break_hit = debug_manager.should_break(session_id, hit_count_node_id, &test_token);
        assert!(!should_break_hit);
        println!("  Hit {}: no break (expected)", i);
    }
    
    // Should break on 3rd hit
    let should_break_on_hit = debug_manager.should_break(session_id, hit_count_node_id, &test_token);
    assert!(should_break_on_hit);
    
    println!("  Hit count breakpoint triggered on 3rd hit");
    println!("  âœ… Breakpoint functionality working correctly!");
}

#[test]
fn test_optimization_recommendations() {
    println!("ðŸ’¡ Optimization Recommendations Test");
    println!("===================================");
    
    let mut debug_manager = DebugManager::new();
    
    println!("ðŸ“Š Testing optimization recommendation generation...");
    
    // Create performance profile for a poorly performing rule
    let rule_id = 123;
    
    // Simulate many evaluations with low success rate
    for i in 1..=100 {
        let mut fact_fields = HashMap::new();
        fact_fields.insert("value".to_string(), FactValue::Integer(i));
        
        let test_fact = Fact {
            id: i as u64,
            data: FactData { fields: fact_fields },
        };
        
        let trace_id = debug_manager.start_trace(rule_id, test_fact.clone());
        
        // Simulate low success rate (only 5% success)
        let execution_result = if i % 20 == 0 {
            ExecutionResult::RuleFired {
                actions_executed: 1,
                facts_created: vec![test_fact],
            }
        } else {
            ExecutionResult::ConditionsNotMet {
                failed_conditions: vec!["Condition failed".to_string()],
            }
        };
        
        debug_manager.complete_trace(trace_id, execution_result);
    }
    
    // Generate optimization recommendations
    let optimizations = debug_manager.generate_optimizations();
    
    println!("  Generated {} optimization recommendations", optimizations.len());
    
    // Should have recommendations for low success rate
    let low_success_rate_opts: Vec<_> = optimizations.iter()
        .filter(|opt| matches!(opt.optimization_type, OptimizationType::RuleReordering))
        .collect();
    
    assert!(!low_success_rate_opts.is_empty());
    
    for opt in &optimizations {
        println!("  {:?}:", opt.optimization_type);
        println!("    Description: {}", opt.description);
        println!("    Potential improvement: {:.1}%", opt.potential_improvement);
        println!("    Priority: {:.2}", opt.priority);
        println!("    Complexity: {:?}", opt.complexity);
        println!("    Affected rules: {:?}", opt.affected_rules);
    }
    
    // Test bottleneck analysis
    let bottlenecks = debug_manager.analyze_bottlenecks(rule_id);
    println!("  Identified {} bottlenecks", bottlenecks.len());
    
    for bottleneck in &bottlenecks {
        println!("    {:?}: {}", bottleneck.bottleneck_type, bottleneck.description);
        println!("      Severity: {:.2}", bottleneck.severity);
        println!("      Suggestion: {}", bottleneck.suggestion);
    }
    
    println!("  âœ… Optimization recommendations working correctly!");
}

#[test]
fn test_debugging_session_management() {
    println!("ðŸ“‹ Debugging Session Management Test");
    println!("===================================");
    
    let mut debug_manager = DebugManager::new();
    
    println!("ðŸ“Š Testing debugging session management...");
    
    // Create multiple sessions with different configurations
    let session1 = debug_manager.create_session(vec![1, 2], None);
    let session2 = debug_manager.create_session(vec![3, 4, 5], Some(DebugConfig {
        enable_tracing: true,
        enable_profiling: false,
        enable_memory_tracking: true,
        max_traces: 500,
        trace_retention_ms: 1800_000, // 30 minutes
        min_execution_time_us: 50,
        enable_token_tracking: false,
        enable_dependency_analysis: true,
    }));
    
    println!("  Created session 1: {}", session1);
    println!("  Created session 2: {}", session2);
    
    // Verify sessions are tracked
    let stats = debug_manager.get_stats();
    assert_eq!(stats.total_sessions, 2);
    
    // Create traces for both sessions
    let mut fact_fields = HashMap::new();
    fact_fields.insert("test_field".to_string(), FactValue::String("test_value".to_string()));
    
    let test_fact = Fact {
        id: 42,
        data: FactData { fields: fact_fields },
    };
    
    // Create traces for session 1
    for rule_id in [1, 2] {
        let trace_id = debug_manager.start_trace(rule_id, test_fact.clone());
        debug_manager.complete_trace(trace_id, ExecutionResult::RuleFired {
            actions_executed: 1,
            facts_created: vec![test_fact.clone()],
        });
    }
    
    // Create traces for session 2
    for rule_id in [3, 4, 5] {
        let trace_id = debug_manager.start_trace(rule_id, test_fact.clone());
        debug_manager.complete_trace(trace_id, ExecutionResult::ConditionsNotMet {
            failed_conditions: vec!["Test condition failed".to_string()],
        });
    }
    
    // Verify traces were created
    let updated_stats = debug_manager.get_stats();
    assert_eq!(updated_stats.total_traces, 5);
    
    println!("  Total traces created: {}", updated_stats.total_traces);
    
    // Get traces for each session
    let session1_traces = debug_manager.get_session_traces(session1);
    let session2_traces = debug_manager.get_session_traces(session2);
    
    println!("  Session 1 traces: {}", session1_traces.len());
    println!("  Session 2 traces: {}", session2_traces.len());
    
    // Test trace cleanup
    debug_manager.cleanup_old_traces();
    
    println!("  Trace cleanup completed");
    
    // All traces should still be there since they're recent
    let final_stats = debug_manager.get_stats();
    assert_eq!(final_stats.total_traces, 5);
    
    println!("  Traces after cleanup: {}", final_stats.total_traces);
    println!("  âœ… Debugging session management working correctly!");
}

#[test]
fn test_memory_usage_tracking() {
    println!("ðŸ’¾ Memory Usage Tracking Test");
    println!("============================");
    
    let mut debug_manager = DebugManager::new();
    
    println!("ðŸ“Š Testing memory usage tracking during execution...");
    
    let rule_id = 789;
    
    // Create test fact
    let mut fact_fields = HashMap::new();
    fact_fields.insert("data_size".to_string(), FactValue::Integer(1000));
    fact_fields.insert("operation".to_string(), FactValue::String("memory_test".to_string()));
    
    let test_fact = Fact {
        id: 1000,
        data: FactData { fields: fact_fields },
    };
    
    // Start trace
    let trace_id = debug_manager.start_trace(rule_id, test_fact.clone());
    
    // Simulate node execution with memory tracking
    let node_execution = NodeExecution {
        node_id: 500,
        node_type: "alpha".to_string(),
        input_tokens: vec![Token::new(test_fact.id)],
        output_tokens: vec![Token::new(test_fact.id)],
        started_at: std::time::SystemTime::now(),
        duration: std::time::Duration::from_millis(5),
        memory_allocated: 2048, // 2KB
        fired_rule: false,
        condition_evaluation: Some(ConditionEvaluation {
            expression: "data_size > 500".to_string(),
            result: true,
            evaluation_time: std::time::Duration::from_micros(100),
            variables: HashMap::new(),
            sub_conditions: Vec::new(),
        }),
        action_execution: None,
    };
    
    debug_manager.record_node_execution(trace_id, node_execution);
    
    // Complete trace
    debug_manager.complete_trace(trace_id, ExecutionResult::RuleFired {
        actions_executed: 1,
        facts_created: vec![test_fact],
    });
    
    // Get performance profile and check memory tracking
    let profile = debug_manager.get_rule_profile(rule_id);
    assert!(profile.is_some());
    
    let profile = profile.unwrap();
    println!("  Rule ID: {}", profile.rule_id);
    println!("  Evaluations: {}", profile.evaluation_count);
    println!("  Average memory usage: {} bytes", profile.average_memory_usage);
    println!("  Peak memory usage: {} bytes", profile.peak_memory_usage);
    
    assert!(profile.average_memory_usage > 0);
    
    println!("  âœ… Memory usage tracking working correctly!");
}