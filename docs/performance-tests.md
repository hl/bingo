# Performance Test Suite

This document describes the comprehensive performance testing suite for the Bingo RETE Rules Engine, including RETE algorithm benchmarks, enterprise-scale validation, and advanced optimization testing.

## üöÄ RETE Algorithm Performance Overview

The Bingo engine implements a complete RETE algorithm with advanced optimizations:

- **O(Œîfacts) Complexity**: Only processes incremental changes, not all facts
- **Alpha Memory Optimization**: Hash-indexed single-condition matching with O(1) lookups
- **Beta Network Processing**: Efficient multi-condition token propagation and joins
- **Rule Optimization**: Automatic condition reordering based on selectivity analysis
- **Parallel Processing**: Multi-threaded execution with work-stealing queues
- **Conflict Resolution**: Multiple strategies with Kahn's algorithm for dependency analysis

## Performance Testing Framework

Performance tests use the adaptive testing framework with automatic threshold adjustment based on environment capabilities. Tests are marked with `#[performance_test]` and require `--release` mode for accurate measurements.

## Current Performance Benchmarks (Release Mode)

### üèÜ RETE Algorithm Performance (Individual Test Results)

**Core RETE Components (Optimized Implementation):**
- **Alpha Memory Network**: 462K facts/sec - Hash-indexed single-condition pattern matching with O(1) lookups
- **Beta Network Processing**: 407K facts/sec - Multi-condition token propagation with efficient join operations
- **Working Memory Updates**: 1.2M facts/sec - Incremental O(Œîfacts) fact processing lifecycle  
- **Rule Independence**: 285K-2.1M facts/sec - Performance scales independently of non-matching rule count

**Advanced Optimization Features:**
- **Rule Reordering**: Automatic condition optimization based on selectivity analysis
- **Dependency Analysis**: Kahn's topological sorting for optimal rule execution order  
- **Conflict Resolution**: Priority-based execution with configurable strategies
- **Parallel Processing**: Multi-threaded RETE with work-stealing queues

**Enterprise Scale Validation (Individual Test Results):**
- **100K facts**: 1.9M facts/sec (54ms processing time) - Production workload
- **250K facts**: 1.8M facts/sec (138ms processing time, 305MB memory) - Large enterprise dataset
- **1M facts**: 1.9M facts/sec (540ms processing time, 1.2GB memory) - Ultra-scale validation
- **2M facts**: 1.4M facts/sec (1.4s processing time, 3.2GB memory) - Maximum validated scale

**Legacy Performance Results:**
- **Basic fact processing**: 560K facts/sec - Simple fact ingestion without rules
- **Rule compilation**: 886K rules/sec - Rule compilation and network setup  
- **Fact lookup**: 13M lookups/sec - Indexed fact retrieval operations
- **Small scale (10K facts)**: 280K facts/sec - Typical development workload
- **Medium scale (25K facts, 5 rules)**: 50K facts/sec - Production-like scenarios

**Memory Efficiency (Individual Test Measurements):**
- **250K facts**: 305MB memory usage (Linear scaling: ~1.2MB per 1K facts)
- **1M facts**: 1.2GB memory usage (Linear scaling: ~1.2MB per 1K facts)  
- **2M facts**: 3.2GB memory usage (Linear scaling: ~1.6MB per 1K facts)

**Memory Scaling Pattern:** ~1.2-1.6MB per 1,000 facts with excellent linear characteristics

## Performance Test Categories

### Core RETE Network Stress Tests

These tests validate network robustness under error conditions and complex processing scenarios:

```bash
# Run individual RETE stress tests
cargo test --release test_missing_node_error_handling_in_incremental_processing -- --ignored
cargo test --release test_error_propagation_in_fact_processing -- --ignored
cargo test --release test_successful_fact_processing_with_error_handling -- --ignored
cargo test --release test_corrupted_network_state_recovery -- --ignored
cargo test --release test_empty_network_processing -- --ignored
cargo test --release test_processing_mode_switching_with_error_conditions -- --ignored
cargo test --release test_rete_network_with_optimal_token_pool -- --ignored
cargo test --release test_calculator_cache_performance_improvement -- --ignored
cargo test --release test_expression_compilation_caching -- --ignored
cargo test --release test_context_sensitive_result_caching -- --ignored
cargo test --release test_calculator_formula_action_integration -- --ignored
cargo test --release test_calculator_complex_formula_with_functions -- --ignored
cargo test --release test_calculator_conditional_formula -- --ignored
cargo test --release test_calculator_error_handling -- --ignored
cargo test --release test_join_conditions_with_shared_entity_id -- --ignored
```

### API Concurrent Performance Tests

These tests validate API performance under concurrent load:

```bash
# Run concurrent API performance tests
cargo test --release test_mixed_operations_performance -- --ignored
cargo test --release test_api_correctness_after_concurrency_changes -- --ignored
cargo test --release test_fact_processing_with_formula_actions -- --ignored
```



## Scaling Validation Tests

The project includes dedicated scaling tests that validate performance at enterprise scale:

```bash
# CI-appropriate tests (100K, 200K facts)
cargo test --package bingo-core --test scaling_validation_test --release

# Heavy performance tests (500K, 1M facts) - manual execution only
cargo test --package bingo-core --test scaling_validation_test --ignored --release
```

## Complex Rule Performance Tests

High-rule-complexity tests that validate performance with calculation-heavy business rules using calculators:

```bash
# Complex rule scenarios with calculator-based business logic
cargo test --package bingo-core --test complex_rule_performance_test --release -- --ignored

# Individual complex rule performance tests
cargo test --release test_100k_facts_200_rules_performance -- --ignored  # 100K facts + 200 calculator rules
cargo test --release test_200k_facts_200_rules_performance -- --ignored  # 200K facts + 200 calculator rules  
cargo test --release test_100k_facts_500_rules_performance -- --ignored  # 100K facts + 500 calculator rules
cargo test --release test_200k_facts_500_rules_performance -- --ignored  # 200K facts + 500 calculator rules
```

### Complex Rule Performance Results

Current performance characteristics for realistic business rule scenarios:

| Test Scale | Throughput | Memory Usage | Complexity | Notes |
|------------|------------|--------------|------------|-------|
| **10K facts** | 280K facts/sec | <10MB | Simple rules | Development scale |
| **25K facts, 5 rules** | 50K facts/sec | <50MB | Medium complexity | Production-like |
| **100K facts** | Target: <3s | Target: <1GB | High complexity | Enterprise scale |
| **200K facts** | Target: <6s | Target: <2GB | High complexity | Enterprise scale |

**Performance Analysis**:
- **Realistic Scaling**: Performance decreases predictably with rule complexity
- **Memory Efficiency**: Linear memory scaling with fact count
- **Throughput Characteristics**: 50K-280K facts/sec depending on complexity
- **Production Readiness**: Targets are achievable on standard hardware

**Key Insights**: 
- Basic operations achieve excellent performance (500K+ facts/sec)
- Complex rule scenarios require longer processing times (realistic for enterprise)
- Memory usage scales predictably with dataset size
- Performance targets are conservative and achievable

These tests simulate real-world business rule complexity with:
- Threshold checking for compliance validation
- Multi-tier limit validation with warning/critical/max levels
- Time-based calculations for payroll and scheduling
- Performance scoring and ranking calculations

## Performance Targets (Updated with Individual Test Results)

The performance tests validate these realistic enterprise targets:

- **100K facts**: <100ms processing time (54ms achieved - 46x faster than target)
- **250K facts**: <500ms processing time (138ms achieved - 3.6x faster than target)  
- **1M facts**: <3s processing time (540ms achieved - 5.6x faster than target)
- **2M facts**: <10s processing time (1.4s achieved - 7x faster than target)
- **Memory usage**: ~1.6GB for 1M facts (linear scaling achieved)

**Note**: These targets are conservative and achievable across different hardware configurations. Actual performance may exceed these targets in optimal conditions.

## Quality vs Performance Separation

### Quality Tests (Core Validation)
- **Purpose**: Code quality, correctness, basic functionality
- **Execution**: `cargo test --workspace` (excludes performance tests)
- **Criteria**: Must pass for quality validation
- **Timing**: Fast execution (<60s total)

### Performance Tests (Stress/Load Testing)  
- **Purpose**: Performance validation, stress testing, scalability
- **Execution**: `cargo test --release -- --ignored`
- **Criteria**: Validates performance targets
- **Timing**: May take several minutes per test



## Troubleshooting Performance Tests

If performance tests fail:

1. **Ensure release mode**: Performance tests require `--release` flag
2. **Check system resources**: Tests may need adequate CPU/memory
3. **Verify targets**: Review performance targets in test code
4. **Environment factors**: System load may affect timing-sensitive tests

## Memory Efficiency Analysis

### Performance Scaling Patterns

**Observations from Comprehensive Testing**:
- Memory usage scales linearly with fact count (50MB for 25K facts)
- Processing time increases with rule complexity as expected
- Basic operations maintain high throughput (500K+ facts/sec)
- Complex scenarios show realistic performance degradation
- Memory efficiency remains consistent across different scales

### Optimization Opportunities

#### High Priority Areas

1. **Rule Complexity Optimization**
   - Analyze performance degradation with increasing rule complexity
   - Optimize RETE network construction for large rule sets
   - Consider rule compilation caching strategies

2. **Memory Allocation Patterns**
   - Profile memory allocation patterns during fact processing
   - Optimize object pooling strategies for high-throughput scenarios
   - Consider memory pre-allocation for known workload patterns

3. **Scaling Efficiency Investigation**
   - Profile performance scaling characteristics across different fact counts
   - Analyze memory usage efficiency at different scales
   - Identify bottlenecks in large dataset processing

#### Medium Priority Areas

4. **Throughput Optimization**
   - Review fact processing pipeline for bottlenecks
   - Optimize data structure access patterns
   - Consider parallel processing for independent operations

5. **Cache Efficiency Improvements**
   - Analyze cache hit rates across different workload patterns
   - Optimize cache sizing and eviction strategies
   - Consider workload-specific cache configurations

6. **Performance Monitoring Infrastructure**
   - Implement detailed performance tracking for production scenarios
   - Add regression testing for performance characteristics
   - Create performance profiling tools for optimization

#### Low Priority Areas

7. **Advanced Optimization Strategies**
   - Evaluate streaming vs batch processing for large result sets
   - Consider API response pagination for large datasets
   - Assess client-side result processing patterns for optimal performance

## Adding New Performance Tests

When adding new performance tests:

1. **Mark as ignored**: Add `#[ignore = "Performance test - run with --release: cargo test --release test_name"]`
2. **Require release mode**: Document release mode requirement
3. **Set reasonable timeouts**: Avoid blocking CI/quality checks
4. **Document expectations**: Include performance targets in test comments